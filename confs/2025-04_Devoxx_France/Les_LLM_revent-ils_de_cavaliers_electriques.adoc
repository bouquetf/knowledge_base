Les LLM rêvent-ils de cavaliers électriques ?

Speacker : Thibaut Giraud - Monsieur Phi

Notion de compréhension.

Les LLM de comprennent rien ? Cavaliers stochastiques ?

Ils se contentent de prédire du prochain token

Donc ils sont trop limité pour comprendre ?

-> Non, pourquoi ?

Analyser le passé

* Identifier les séquences locales
* Identifier les probabilités d’occurences
* Identifier à l’aide des connaissances de ce que ça peut vouloir dire. Ex: les coups aux échecs

Analyse d’une suite d’informations. Degrés de compréhension: 

. Degré 0 : bruit
. Degré 1 : Patterns de surface
. Degré 2 : connaissance basique + compréhension du système d’écriture. Ce qu’il manque : représentation de ce que ça représente
. Degré 3 : Représentation + connassance stratégique -> Compréhension de la séquence et de ce que ça représente.

Argument: "Prédire le prochain token ne permet pas de comprendre"

C’est faux. Ex: coups d’échecs. Représentation + connaissance stratégiques. 

Les LLM manquent de rerésentation intermédiaires ?

Certains modèles les supportent visiblement. 
Ex: les échecs. GPT-3.5 sorti il y a 2 ans. Septembre 2022 -> 1800 ELO

Apriori, les LLM arrivent à se créer une représentation mentale de l’évolution de la suite. 